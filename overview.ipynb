{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the gaussian distributions\n",
    "mean1 = [0, 0]\n",
    "cov1 = [[1, 0], [0, 100]]  # diagonal covariance\n",
    "\n",
    "mean2 = [10, 10]\n",
    "cov2 = [[10, 0], [0, 20]]  # diagonal covariance\n",
    "\n",
    "# Generate the datasets\n",
    "mc1 = np.random.multivariate_normal(mean1, cov1, 50000)\n",
    "mc2 = np.random.multivariate_normal(mean2, cov2, 50000)\n",
    "\n",
    "# Plot the datasets\n",
    "plt.scatter(mc1[:, 0], mc1[:, 1], s=1)\n",
    "plt.scatter(mc2[:, 0], mc2[:, 1], s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the labels\n",
    "mc1_labels = np.zeros(len(mc1))\n",
    "mc2_labels = np.ones(len(mc2))\n",
    "\n",
    "# Merge the datasets\n",
    "X = np.concatenate((mc1, mc2))\n",
    "y = np.concatenate((mc1_labels, mc2_labels))\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    \"n_estimators\": [10, 50, 100, 200, 300, 500],\n",
    "}\n",
    "\n",
    "# Create the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Create the grid search object\n",
    "grid = GridSearchCV(model, params, scoring=\"accuracy\", n_jobs=-1, cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Print the best score\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Get best estimator\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# Score the model\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [value for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the probability density functions of the classifier\n",
    "y_pred_1 = model.predict_proba(X[y == 0])\n",
    "y_pred_2 = model.predict_proba(X[y == 1])\n",
    "n_bins = 100\n",
    "plt.hist(\n",
    "    y_pred_1[:, 1], bins=n_bins, alpha=0.5, label=\"mc1\", log=True, density=True\n",
    ")\n",
    "plt.hist(\n",
    "    y_pred_2[:, 1], bins=n_bins, alpha=0.5, label=\"mc2\", log=True, density=True\n",
    ")\n",
    "plt.ylim(1e-2, 2e2)\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the probability density functions of the classifier\n",
    "y_pred_1 = model.predict_proba(X_test[y_test == 0])\n",
    "y_pred_2 = model.predict_proba(X_test[y_test == 1])\n",
    "n_bins = 100\n",
    "plt.hist(\n",
    "    y_pred_1[:, 1], bins=n_bins, alpha=0.5, label=\"mc1\", log=True, density=True\n",
    ")\n",
    "plt.hist(\n",
    "    y_pred_2[:, 1], bins=n_bins, alpha=0.5, label=\"mc2\", log=True, density=True\n",
    ")\n",
    "plt.ylim(1e-2, 2e2)\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data1 = np.random.multivariate_normal(mean1, cov1, 90000000)\n",
    "new_data2 = np.random.multivariate_normal(mean2, cov2, 90000000)\n",
    "\n",
    "new_labels1 = np.zeros(len(new_data1))\n",
    "new_labels2 = np.ones(len(new_data2))\n",
    "\n",
    "new_X = np.concatenate((new_data1, new_data2))\n",
    "new_y = np.concatenate((new_labels1, new_labels2))\n",
    "\n",
    "new_y_pred = model.predict_proba(new_X)[:, 1]\n",
    "new_y_pred_1 = model.predict_proba(new_data1)[:, 1]\n",
    "new_y_pred_2 = model.predict_proba(new_data2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the y axis limits\n",
    "plt.hist(\n",
    "    new_y_pred_1, bins=n_bins, alpha=0.5, label=\"mc1\", log=True, density=True\n",
    ")\n",
    "plt.hist(\n",
    "    new_y_pred_2, bins=n_bins, alpha=0.5, label=\"mc2\", log=True, density=True\n",
    ")\n",
    "plt.ylim(1e-3, 2e2)\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the y axis limits\n",
    "n_bins = int(1 + 3.3 * np.log(len(new_y_pred_1)))  # sturge's rule\n",
    "plt.hist(\n",
    "    new_y_pred_1, bins=n_bins, alpha=0.5, label=\"mc1\", log=True, density=True\n",
    ")\n",
    "plt.hist(\n",
    "    new_y_pred_2, bins=n_bins, alpha=0.5, label=\"mc2\", log=True, density=True\n",
    ")\n",
    "plt.ylim(1e-3, 2e2)\n",
    "plt.xlim(0, 1)\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Fit a normal distribution to the data\n",
    "params = stats.norm.fit(y_pred_1[:, 1])\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(y_pred_1[:, 1], bins=61, density=True, alpha=0.6, color=\"g\", log=True)\n",
    "\n",
    "# Plot the PDF\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, *params)\n",
    "plt.plot(x, p, \"k\", linewidth=2)\n",
    "\n",
    "plt.ylim(1e-3, 2e2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Fit a Weibull distribution to the data\n",
    "params = stats.weibull_min.fit([x for x in y_pred_1[:, 1] if x < 0.5])\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Plot the histogram\n",
    "plt.hist(y_pred_1[:, 1], bins=61, density=True, alpha=0.6, color=\"g\", log=True)\n",
    "\n",
    "# Plot the PDF\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.weibull_min.pdf(x, *params)\n",
    "plt.plot(x, p, \"k\", linewidth=2)\n",
    "\n",
    "plt.ylim(1e-3, 2e2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the CDF of the data\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(\n",
    "    y_pred_1[:, 1],\n",
    "    bins=61,\n",
    "    density=True,\n",
    "    histtype=\"step\",\n",
    "    cumulative=True,\n",
    "    label=\"CDF\",\n",
    ")\n",
    "# Add the cdf of the fitted distribution\n",
    "plt.plot(\n",
    "    x, p.cumsum() / p.cumsum().max(), \"k--\", linewidth=2, label=\"CDF fitted\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Fit an Inverse Gamma distribution to the data\n",
    "params = stats.invgamma.fit([x for x in y_pred_1[:, 1] if x < 0.5])\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(y_pred_1[:, 1], bins=61, density=True, alpha=0.6, color=\"g\", log=True)\n",
    "\n",
    "# Plot the PDF\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.invgamma.pdf(x, *params)\n",
    "plt.plot(x, p, \"k\", linewidth=2)\n",
    "\n",
    "plt.ylim(1e-3, 2e2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the CDF of the data\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(\n",
    "    y_pred_1[:, 1],\n",
    "    bins=61,\n",
    "    density=True,\n",
    "    histtype=\"step\",\n",
    "    cumulative=True,\n",
    "    label=\"CDF\",\n",
    ")\n",
    "# Add the cdf of the fitted distribution\n",
    "plt.plot(\n",
    "    x, p.cumsum() / p.cumsum().max(), \"k--\", linewidth=2, label=\"CDF fitted\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats._continuous_distns import _distn_names\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Create models from data\n",
    "def best_fit_distribution(data, bins=200, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Best holders\n",
    "    best_distributions = []\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for ii, distribution in enumerate([d for d in _distn_names if not d in ['levy_stable', 'studentized_range']]):\n",
    "\n",
    "        print(\"{:>3} / {:<3}: {}\".format( ii+1, len(_distn_names), distribution ))\n",
    "\n",
    "        distribution = getattr(st, distribution)\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                \n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "                \n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "                \n",
    "                # if axis pass in add to plot\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    end\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                best_distributions.append((distribution, params, sse))\n",
    "        \n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    return sorted(best_distributions, key=lambda x:x[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function\"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = (\n",
    "        dist.ppf(0.000001, *arg, loc=loc, scale=scale)\n",
    "        if arg\n",
    "        else dist.ppf(0.00001, loc=loc, scale=scale)\n",
    "    )\n",
    "    end = (\n",
    "        dist.ppf(0.99999999, *arg, loc=loc, scale=scale)\n",
    "        if arg\n",
    "        else dist.ppf(0.9999999, loc=loc, scale=scale)\n",
    "    )\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from statsmodels datasets\n",
    "data = pd.DataFrame(y_pred_1[:, 1])\n",
    "\n",
    "# Plot for comparison\n",
    "plt.figure(figsize=(3, 2))\n",
    "ax = data.plot(\n",
    "    kind=\"hist\",\n",
    "    bins=50,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=list(matplotlib.rcParams[\"axes.prop_cycle\"])[1][\"color\"],\n",
    "    log=True,\n",
    ")\n",
    "# Save plot limits\n",
    "dataYLim = ax.get_ylim()\n",
    "# Find best fit distribution\n",
    "best_distibutions = best_fit_distribution(data, 200, ax)\n",
    "best_dist = best_distibutions[0]\n",
    "\n",
    "# Update plots\n",
    "ax.set_ylim(dataYLim)\n",
    "ax.set_title(\"All Fitted Distributions\")\n",
    "ax.set_xlabel(\"Temp (°C)\")\n",
    "ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make PDF with best params\n",
    "pdf = make_pdf(best_dist[0], best_dist[1])\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = pdf.plot(lw=2, label=\"PDF\", legend=True)\n",
    "data.plot(\n",
    "    kind=\"hist\",\n",
    "    bins=50,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    label=\"Data\",\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "param_names = (\n",
    "    (best_dist[0].shapes + \", loc, scale\").split(\", \")\n",
    "    if best_dist[0].shapes\n",
    "    else [\"loc\", \"scale\"]\n",
    ")\n",
    "param_str = \", \".join(\n",
    "    [\"{}={:0.2f}\".format(k, v) for k, v in zip(param_names, best_dist[1])]\n",
    ")\n",
    "dist_str = \"{}({})\".format(best_dist[0].name, param_str)\n",
    "\n",
    "ax.set_title(\"best fit distribution \\n\" + dist_str)\n",
    "ax.set_xlabel(\"Temp. (°C)\")\n",
    "ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
